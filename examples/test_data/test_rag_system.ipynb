{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextReadingRAG System Testing Notebook\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Upload and ingest documents (PDF, DOCX, TXT)\n",
    "2. Query the system with both English and Chinese queries\n",
    "3. Test hybrid retrieval modes\n",
    "4. Analyze retrieval results\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(os.getcwd())\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from src.core.config import Settings\n",
    "from src.rag.ingestion import DocumentIngestionService, DocumentLoader\n",
    "from src.rag.retrieval import HybridRetrievalService, RetrievalMode, FusionMethod\n",
    "from src.rag.vector_store import ChromaVectorStore\n",
    "from src.rag.language_utils import detect_language\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize settings\n",
    "settings = Settings()\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  App Name: {settings.app.app_name}\")\n",
    "print(f\"  OpenAI Model: {settings.llm.openai_model}\")\n",
    "print(f\"  Embedding Model: {settings.llm.openai_embedding_model}\")\n",
    "print(f\"  Chroma Collection: {settings.rag.chroma_collection_name}\")\n",
    "print(f\"  Supported Languages: {settings.rag.supported_languages}\")\n",
    "print(f\"  Language Detection: {settings.rag.enable_language_detection}\")\n",
    "print(f\"  Chunk Size (EN): {settings.rag.chunk_size}\")\n",
    "print(f\"  Chunk Size (ZH): {settings.rag.chinese_chunk_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector store\n",
    "vector_store = ChromaVectorStore(\n",
    "    host=settings.rag.chroma_host,\n",
    "    port=settings.rag.chroma_port,\n",
    "    persist_directory=settings.rag.chroma_persist_directory,\n",
    "    settings=settings,\n",
    ")\n",
    "\n",
    "print(\"✓ Vector store initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ingestion service\n",
    "ingestion_service = DocumentIngestionService(\n",
    "    settings=settings,\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "print(\"✓ Ingestion service initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize retrieval service\n",
    "retrieval_service = HybridRetrievalService(\n",
    "    vector_store=vector_store,\n",
    "    settings=settings,\n",
    ")\n",
    "\n",
    "print(\"✓ Retrieval service initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Upload and Ingestion\n",
    "\n",
    "### Create Sample Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test documents directory\n",
    "test_docs_dir = project_root / \"test_documents\"\n",
    "test_docs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Test documents directory: {test_docs_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample English document\n",
    "english_doc = test_docs_dir / \"ai_introduction_en.txt\"\n",
    "english_doc.write_text(\"\"\"\n",
    "Introduction to Artificial Intelligence\n",
    "\n",
    "Artificial Intelligence (AI) is a branch of computer science that aims to create \n",
    "intelligent machines that can perform tasks that typically require human intelligence. \n",
    "These tasks include visual perception, speech recognition, decision-making, and \n",
    "language translation.\n",
    "\n",
    "Machine Learning\n",
    "\n",
    "Machine learning is a subset of AI that enables computers to learn from data without \n",
    "being explicitly programmed. It uses algorithms to identify patterns in data and make \n",
    "predictions or decisions based on those patterns.\n",
    "\n",
    "Deep Learning\n",
    "\n",
    "Deep learning is a specialized form of machine learning that uses artificial neural \n",
    "networks with multiple layers. These deep neural networks can process complex data \n",
    "such as images, audio, and text with remarkable accuracy.\n",
    "\n",
    "Natural Language Processing\n",
    "\n",
    "Natural Language Processing (NLP) is a field of AI that focuses on enabling computers \n",
    "to understand, interpret, and generate human language. NLP powers applications like \n",
    "chatbots, translation services, and sentiment analysis.\n",
    "\n",
    "Computer Vision\n",
    "\n",
    "Computer vision is another important area of AI that enables machines to interpret \n",
    "and understand visual information from the world. It's used in applications like \n",
    "facial recognition, autonomous vehicles, and medical image analysis.\n",
    "\"\"\", encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Created: {english_doc.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample Chinese document (Traditional)\n",
    "chinese_doc = test_docs_dir / \"ai_introduction_zh.txt\"\n",
    "chinese_doc.write_text(\"\"\"\n",
    "人工智能簡介\n",
    "\n",
    "人工智能（AI）是計算機科學的一個分支，旨在創建能夠執行通常需要人類智能的任務的智能機器。\n",
    "這些任務包括視覺感知、語音識別、決策制定和語言翻譯。\n",
    "\n",
    "機器學習\n",
    "\n",
    "機器學習是人工智能的一個子集，使計算機能夠從數據中學習而無需明確編程。它使用算法來識別\n",
    "數據中的模式，並根據這些模式進行預測或決策。\n",
    "\n",
    "深度學習\n",
    "\n",
    "深度學習是機器學習的一種特殊形式，使用具有多個層次的人工神經網絡。這些深度神經網絡可以\n",
    "以驚人的準確性處理複雜的數據，如圖像、音頻和文本。\n",
    "\n",
    "自然語言處理\n",
    "\n",
    "自然語言處理（NLP）是人工智能的一個領域，專注於使計算機能夠理解、解釋和生成人類語言。\n",
    "NLP 為聊天機器人、翻譯服務和情感分析等應用提供動力。\n",
    "\n",
    "計算機視覺\n",
    "\n",
    "計算機視覺是人工智能的另一個重要領域，使機器能夠解釋和理解來自世界的視覺信息。它用於\n",
    "面部識別、自動駕駛汽車和醫療影像分析等應用。\n",
    "\"\"\", encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Created: {chinese_doc.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mixed language document\n",
    "mixed_doc = test_docs_dir / \"rag_systems.txt\"\n",
    "mixed_doc.write_text(\"\"\"\n",
    "Retrieval-Augmented Generation (RAG) Systems\n",
    "\n",
    "RAG systems combine the power of large language models with external knowledge bases \n",
    "to provide more accurate and contextually relevant responses. The system retrieves \n",
    "relevant documents from a vector database and uses them to augment the generation process.\n",
    "\n",
    "檢索增強生成系統\n",
    "\n",
    "RAG 系統結合了大型語言模型的強大功能和外部知識庫，以提供更準確和上下文相關的響應。\n",
    "該系統從向量數據庫中檢索相關文檔，並使用它們來增強生成過程。\n",
    "\n",
    "Key Components:\n",
    "1. Document Ingestion - Processing and chunking documents\n",
    "2. Vector Embeddings - Converting text to numerical vectors\n",
    "3. Retrieval - Finding relevant documents using similarity search\n",
    "4. Generation - Creating responses using retrieved context\n",
    "\n",
    "主要組成部分：\n",
    "1. 文檔攝取 - 處理和分塊文檔\n",
    "2. 向量嵌入 - 將文本轉換為數值向量\n",
    "3. 檢索 - 使用相似性搜索找到相關文檔\n",
    "4. 生成 - 使用檢索到的上下文創建響應\n",
    "\"\"\", encoding='utf-8')\n",
    "\n",
    "print(f\"✓ Created: {mixed_doc.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest English document\n",
    "print(\"Ingesting English document...\")\n",
    "result_en = await ingestion_service.ingest_file(\n",
    "    file_path=str(english_doc),\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nEnglish Document Ingestion Results:\")\n",
    "print(f\"  File: {result_en['filename']}\")\n",
    "print(f\"  Nodes created: {result_en['nodes_created']}\")\n",
    "print(f\"  Processing time: {result_en['processing_time_seconds']:.2f}s\")\n",
    "print(f\"  Collection: {result_en['collection_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest Chinese document\n",
    "print(\"Ingesting Chinese document...\")\n",
    "result_zh = await ingestion_service.ingest_file(\n",
    "    file_path=str(chinese_doc),\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nChinese Document Ingestion Results:\")\n",
    "print(f\"  File: {result_zh['filename']}\")\n",
    "print(f\"  Nodes created: {result_zh['nodes_created']}\")\n",
    "print(f\"  Processing time: {result_zh['processing_time_seconds']:.2f}s\")\n",
    "print(f\"  Collection: {result_zh['collection_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest mixed document\n",
    "print(\"Ingesting mixed language document...\")\n",
    "result_mixed = await ingestion_service.ingest_file(\n",
    "    file_path=str(mixed_doc),\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nMixed Document Ingestion Results:\")\n",
    "print(f\"  File: {result_mixed['filename']}\")\n",
    "print(f\"  Nodes created: {result_mixed['nodes_created']}\")\n",
    "print(f\"  Processing time: {result_mixed['processing_time_seconds']:.2f}s\")\n",
    "print(f\"  Collection: {result_mixed['collection_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ingestion statistics\n",
    "stats = ingestion_service.get_ingestion_stats()\n",
    "\n",
    "print(\"\\nCollection Statistics:\")\n",
    "pprint(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query Testing\n",
    "\n",
    "### English Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test English query - Machine Learning\n",
    "query_en_1 = \"What is machine learning?\"\n",
    "\n",
    "print(f\"Query: {query_en_1}\")\n",
    "print(f\"Detected language: {detect_language(query_en_1)}\")\n",
    "print(\"\\nRetrieving...\")\n",
    "\n",
    "results_en_1 = await retrieval_service.retrieve(\n",
    "    query=query_en_1,\n",
    "    mode=RetrievalMode.HYBRID,\n",
    "    top_k=3,\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nRetrieved {len(results_en_1)} results:\\n\")\n",
    "for i, result in enumerate(results_en_1, 1):\n",
    "    print(f\"Result {i} (Score: {result.score:.4f}):\")\n",
    "    print(f\"  Text: {result.node.text[:200]}...\")\n",
    "    print(f\"  Language: {result.node.metadata.get('language', 'N/A')}\")\n",
    "    print(f\"  Method: {result.node.metadata.get('retrieval_method', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test English query - Deep Learning\n",
    "query_en_2 = \"Explain deep learning and neural networks\"\n",
    "\n",
    "print(f\"Query: {query_en_2}\")\n",
    "print(f\"Detected language: {detect_language(query_en_2)}\")\n",
    "print(\"\\nRetrieving...\")\n",
    "\n",
    "results_en_2 = await retrieval_service.retrieve(\n",
    "    query=query_en_2,\n",
    "    mode=RetrievalMode.HYBRID,\n",
    "    top_k=3,\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nRetrieved {len(results_en_2)} results:\\n\")\n",
    "for i, result in enumerate(results_en_2, 1):\n",
    "    print(f\"Result {i} (Score: {result.score:.4f}):\")\n",
    "    print(f\"  Text: {result.node.text[:200]}...\")\n",
    "    print(f\"  Language: {result.node.metadata.get('language', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese Queries (繁體中文)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Chinese query - Machine Learning\n",
    "query_zh_1 = \"什麼是機器學習？\"\n",
    "\n",
    "print(f\"Query: {query_zh_1}\")\n",
    "print(f\"Detected language: {detect_language(query_zh_1)}\")\n",
    "print(\"\\nRetrieving...\")\n",
    "\n",
    "results_zh_1 = await retrieval_service.retrieve(\n",
    "    query=query_zh_1,\n",
    "    mode=RetrievalMode.HYBRID,\n",
    "    top_k=3,\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nRetrieved {len(results_zh_1)} results:\\n\")\n",
    "for i, result in enumerate(results_zh_1, 1):\n",
    "    print(f\"Result {i} (Score: {result.score:.4f}):\")\n",
    "    print(f\"  Text: {result.node.text[:200]}...\")\n",
    "    print(f\"  Language: {result.node.metadata.get('language', 'N/A')}\")\n",
    "    print(f\"  Method: {result.node.metadata.get('retrieval_method', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Chinese query - Natural Language Processing\n",
    "query_zh_2 = \"自然語言處理有什麼應用？\"\n",
    "\n",
    "print(f\"Query: {query_zh_2}\")\n",
    "print(f\"Detected language: {detect_language(query_zh_2)}\")\n",
    "print(\"\\nRetrieving...\")\n",
    "\n",
    "results_zh_2 = await retrieval_service.retrieve(\n",
    "    query=query_zh_2,\n",
    "    mode=RetrievalMode.HYBRID,\n",
    "    top_k=3,\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nRetrieved {len(results_zh_2)} results:\\n\")\n",
    "for i, result in enumerate(results_zh_2, 1):\n",
    "    print(f\"Result {i} (Score: {result.score:.4f}):\")\n",
    "    print(f\"  Text: {result.node.text[:200]}...\")\n",
    "    print(f\"  Language: {result.node.metadata.get('language', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Chinese query - RAG systems\n",
    "query_zh_3 = \"RAG 系統的主要組成部分是什麼？\"\n",
    "\n",
    "print(f\"Query: {query_zh_3}\")\n",
    "print(f\"Detected language: {detect_language(query_zh_3)}\")\n",
    "print(\"\\nRetrieving...\")\n",
    "\n",
    "results_zh_3 = await retrieval_service.retrieve(\n",
    "    query=query_zh_3,\n",
    "    mode=RetrievalMode.HYBRID,\n",
    "    top_k=3,\n",
    "    collection_name=settings.rag.chroma_collection_name,\n",
    ")\n",
    "\n",
    "print(f\"\\nRetrieved {len(results_zh_3)} results:\\n\")\n",
    "for i, result in enumerate(results_zh_3, 1):\n",
    "    print(f\"Result {i} (Score: {result.score:.4f}):\")\n",
    "    print(f\"  Text: {result.node.text[:200]}...\")\n",
    "    print(f\"  Language: {result.node.metadata.get('language', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Retrieval Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different retrieval modes with the same query\n",
    "test_query = \"深度學習如何處理複雜數據？\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "modes = [\n",
    "    RetrievalMode.VECTOR_ONLY,\n",
    "    RetrievalMode.BM25_ONLY,\n",
    "    RetrievalMode.HYBRID,\n",
    "]\n",
    "\n",
    "for mode in modes:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Retrieval Mode: {mode.value.upper()}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    results = await retrieval_service.retrieve(\n",
    "        query=test_query,\n",
    "        mode=mode,\n",
    "        top_k=2,\n",
    "        collection_name=settings.rag.chroma_collection_name,\n",
    "    )\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\nResult {i} (Score: {result.score:.4f}):\")\n",
    "        print(f\"  {result.node.text[:150]}...\")\n",
    "        print(f\"  Retrieval time: {result.node.metadata.get('retrieval_time_ms', 'N/A')}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced: Custom Retrieval Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different alpha values (dense vs sparse weight)\n",
    "test_query = \"computer vision applications\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "alphas = [0.0, 0.5, 1.0]  # 0.0 = sparse only, 0.5 = balanced, 1.0 = dense only\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\nAlpha = {alpha} ({'Sparse only' if alpha == 0.0 else 'Dense only' if alpha == 1.0 else 'Balanced'}):\")\n",
    "    \n",
    "    results = await retrieval_service.retrieve(\n",
    "        query=test_query,\n",
    "        mode=RetrievalMode.HYBRID,\n",
    "        alpha=alpha,\n",
    "        top_k=2,\n",
    "        collection_name=settings.rag.chroma_collection_name,\n",
    "    )\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"  {i}. Score: {result.score:.4f} | {result.node.text[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Testing with Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries in both languages\n",
    "test_queries = [\n",
    "    (\"What is artificial intelligence?\", \"en\"),\n",
    "    (\"什麼是人工智能？\", \"zh\"),\n",
    "    (\"How does machine learning work?\", \"en\"),\n",
    "    (\"機器學習如何運作？\", \"zh\"),\n",
    "    (\"What are the applications of NLP?\", \"en\"),\n",
    "    (\"自然語言處理有哪些應用？\", \"zh\"),\n",
    "]\n",
    "\n",
    "print(\"Batch Query Testing\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for query, expected_lang in test_queries:\n",
    "    detected_lang = detect_language(query)\n",
    "    \n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Expected: {expected_lang} | Detected: {detected_lang}\")\n",
    "    \n",
    "    results = await retrieval_service.retrieve(\n",
    "        query=query,\n",
    "        mode=RetrievalMode.HYBRID,\n",
    "        top_k=1,\n",
    "        collection_name=settings.rag.chroma_collection_name,\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        top_result = results[0]\n",
    "        print(f\"Top result (Score: {top_result.score:.4f}):\")\n",
    "        print(f\"  {top_result.node.text[:120]}...\")\n",
    "    else:\n",
    "        print(\"  No results found\")\n",
    "    \n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrieval Statistics and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get retrieval statistics\n",
    "retrieval_stats = retrieval_service.get_retrieval_stats(\n",
    "    collection_name=settings.rag.chroma_collection_name\n",
    ")\n",
    "\n",
    "print(\"Retrieval Service Statistics:\\n\")\n",
    "pprint(retrieval_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the test collection\n",
    "# vector_store.delete_collection(settings.rag.chroma_collection_name)\n",
    "# print(f\"✓ Deleted collection: {settings.rag.chroma_collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete test documents\n",
    "# import shutil\n",
    "# if test_docs_dir.exists():\n",
    "#     shutil.rmtree(test_docs_dir)\n",
    "#     print(f\"✓ Deleted test documents directory: {test_docs_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "✅ Document ingestion with language detection  \n",
    "✅ English and Chinese query support  \n",
    "✅ Multiple retrieval modes (vector, BM25, hybrid)  \n",
    "✅ Retrieval parameter tuning (alpha, top_k)  \n",
    "✅ Batch query testing  \n",
    "✅ Performance statistics  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Upload your own documents (PDF, DOCX, TXT)\n",
    "2. Experiment with different chunk sizes for different languages\n",
    "3. Try query expansion for better retrieval results\n",
    "4. Implement reranking for improved accuracy\n",
    "5. Test with larger document collections\n",
    "\n",
    "### Tips\n",
    "\n",
    "- For Chinese documents, use smaller chunk sizes (256 chars vs 512 for English)\n",
    "- Hybrid retrieval often provides the best results\n",
    "- Adjust alpha based on your use case (semantic vs keyword matching)\n",
    "- Monitor retrieval times and adjust top_k accordingly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
